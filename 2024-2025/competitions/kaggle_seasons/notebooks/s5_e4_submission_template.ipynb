{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcG9WwtPMQb3"
      },
      "source": [
        "# Imports and Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0xwGvVLMcgl"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Podcast_Name</th>\n",
              "      <th>Episode_Title</th>\n",
              "      <th>Episode_Length_minutes</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Host_Popularity_percentage</th>\n",
              "      <th>Publication_Day</th>\n",
              "      <th>Publication_Time</th>\n",
              "      <th>Guest_Popularity_percentage</th>\n",
              "      <th>Number_of_Ads</th>\n",
              "      <th>Episode_Sentiment</th>\n",
              "      <th>Listening_Time_minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Mystery Matters</td>\n",
              "      <td>Episode 98</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True Crime</td>\n",
              "      <td>74.81</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>Night</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>31.41998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Joke Junction</td>\n",
              "      <td>Episode 26</td>\n",
              "      <td>119.80</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>66.95</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>75.95</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Negative</td>\n",
              "      <td>88.01241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Study Sessions</td>\n",
              "      <td>Episode 16</td>\n",
              "      <td>73.90</td>\n",
              "      <td>Education</td>\n",
              "      <td>69.97</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>Evening</td>\n",
              "      <td>8.97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Negative</td>\n",
              "      <td>44.92531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Digital Digest</td>\n",
              "      <td>Episode 45</td>\n",
              "      <td>67.17</td>\n",
              "      <td>Technology</td>\n",
              "      <td>57.22</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Morning</td>\n",
              "      <td>78.70</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>46.27824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mind &amp; Body</td>\n",
              "      <td>Episode 86</td>\n",
              "      <td>110.51</td>\n",
              "      <td>Health</td>\n",
              "      <td>80.07</td>\n",
              "      <td>Monday</td>\n",
              "      <td>Afternoon</td>\n",
              "      <td>58.68</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>75.61031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id     Podcast_Name Episode_Title  Episode_Length_minutes       Genre  \\\n",
              "0   0  Mystery Matters    Episode 98                     NaN  True Crime   \n",
              "1   1    Joke Junction    Episode 26                  119.80      Comedy   \n",
              "2   2   Study Sessions    Episode 16                   73.90   Education   \n",
              "3   3   Digital Digest    Episode 45                   67.17  Technology   \n",
              "4   4      Mind & Body    Episode 86                  110.51      Health   \n",
              "\n",
              "   Host_Popularity_percentage Publication_Day Publication_Time  \\\n",
              "0                       74.81        Thursday            Night   \n",
              "1                       66.95        Saturday        Afternoon   \n",
              "2                       69.97         Tuesday          Evening   \n",
              "3                       57.22          Monday          Morning   \n",
              "4                       80.07          Monday        Afternoon   \n",
              "\n",
              "   Guest_Popularity_percentage  Number_of_Ads Episode_Sentiment  \\\n",
              "0                          NaN            0.0          Positive   \n",
              "1                        75.95            2.0          Negative   \n",
              "2                         8.97            0.0          Negative   \n",
              "3                        78.70            2.0          Positive   \n",
              "4                        58.68            3.0           Neutral   \n",
              "\n",
              "   Listening_Time_minutes  \n",
              "0                31.41998  \n",
              "1                88.01241  \n",
              "2                44.92531  \n",
              "3                46.27824  \n",
              "4                75.61031  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ElaN-hf4Zo"
      },
      "source": [
        "## (Optional) Data Enhancement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NolaSI-LNrvn"
      },
      "source": [
        "# (Optional) EDA (Explorative Data Analysis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-WN9BCaLi6G"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl9qGg6xLuAj"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fill NaN Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# concatenate all data to get fill values and then split again into no NaN value datasets\n",
        "num_cols = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "cat_cols = ['Podcast_Name', 'Episode_Title', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n",
        "\n",
        "combined = pd.concat([df_train, df_test], sort=False).reset_index(drop=True)\n",
        "\n",
        "# fill numerical NaN values with median\n",
        "for col in num_cols:\n",
        "    combined[col] = combined[col].fillna(combined[col].median())\n",
        "\n",
        "# fill categorical NaN values with \"-1\", to avoid bias which would occur by filling with mode\n",
        "for col in cat_cols:\n",
        "    combined[col] = combined[col].astype('category').cat.codes\n",
        "\n",
        "# split back into train/test\n",
        "df_train_processed = combined.iloc[:len(df_train)].copy()\n",
        "df_test_processed = combined.iloc[len(df_train):].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VNk3rHANA7V"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaoW1sawNhXQ"
      },
      "source": [
        "## (Optional) Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbTvPMrFNPp-"
      },
      "source": [
        "## Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_train_processed.drop(['id', 'Listening_Time_minutes'], axis=1)\n",
        "y = df_train_processed['Listening_Time_minutes']\n",
        "X_test = df_test_processed.drop(['id', 'Listening_Time_minutes'], axis=1, errors='ignore')\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHs3ag34OiuD"
      },
      "source": [
        "# Model Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2axEbRDYO-Yd"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNzDjxg6PTPi"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OZ18c283XTr0"
      },
      "outputs": [],
      "source": [
        "# Model training\n",
        "# Model predictions\n",
        "# Performance summary\n",
        "\n",
        "### Recommended: complete the model training and model prediction during cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQIBLbk6PXBv"
      },
      "source": [
        "## Model Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRhJubybPbF3"
      },
      "source": [
        "### Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6u5CBo2gNIJ"
      },
      "source": [
        "### (Optional) Parameter Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WqihjvTeQAt"
      },
      "source": [
        "# (Optional) Ensemble Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdIR1v9chUTT"
      },
      "source": [
        "## Training & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1 - LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttrain's rmse: 13.03\tvalid's rmse: 13.0609\n",
            "[200]\ttrain's rmse: 12.9199\tvalid's rmse: 13.0283\n",
            "[300]\ttrain's rmse: 12.8297\tvalid's rmse: 13.0069\n",
            "[400]\ttrain's rmse: 12.7531\tvalid's rmse: 12.9914\n",
            "[500]\ttrain's rmse: 12.6811\tvalid's rmse: 12.9789\n",
            "[600]\ttrain's rmse: 12.6157\tvalid's rmse: 12.9718\n",
            "[700]\ttrain's rmse: 12.5475\tvalid's rmse: 12.9614\n",
            "[800]\ttrain's rmse: 12.4848\tvalid's rmse: 12.9519\n",
            "[900]\ttrain's rmse: 12.4291\tvalid's rmse: 12.9445\n",
            "[1000]\ttrain's rmse: 12.3753\tvalid's rmse: 12.9364\n",
            "[1100]\ttrain's rmse: 12.3251\tvalid's rmse: 12.9324\n",
            "[1200]\ttrain's rmse: 12.2759\tvalid's rmse: 12.926\n",
            "[1300]\ttrain's rmse: 12.2276\tvalid's rmse: 12.9208\n",
            "[1400]\ttrain's rmse: 12.1815\tvalid's rmse: 12.915\n",
            "[1500]\ttrain's rmse: 12.138\tvalid's rmse: 12.912\n",
            "[1600]\ttrain's rmse: 12.0904\tvalid's rmse: 12.9077\n",
            "[1700]\ttrain's rmse: 12.0483\tvalid's rmse: 12.9057\n",
            "[1800]\ttrain's rmse: 12.0084\tvalid's rmse: 12.9018\n",
            "[1900]\ttrain's rmse: 11.9661\tvalid's rmse: 12.8993\n",
            "[2000]\ttrain's rmse: 11.9259\tvalid's rmse: 12.8961\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1996]\ttrain's rmse: 11.9282\tvalid's rmse: 12.8961\n",
            "LightGBM Validation RMSE: 12.896076615959402\n"
          ]
        }
      ],
      "source": [
        "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "lgb_val = lgb.Dataset(X_val, label=y_val, reference=lgb_train)\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'seed': 100\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    lgb_params,\n",
        "    lgb_train,\n",
        "    num_boost_round=2000,\n",
        "    valid_sets=[lgb_train, lgb_val],\n",
        "    valid_names=['train', 'valid'],\n",
        "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
        ")\n",
        "\n",
        "lgb_pred_val = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
        "lgb_rmse = np.sqrt(mean_squared_error(y_val, lgb_pred_val))\n",
        "print(\"LightGBM Validation RMSE:\", lgb_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model 2- Linear Regression (With Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression Validation RMSE: 13.351701011642964\n"
          ]
        }
      ],
      "source": [
        "lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lr', LinearRegression())\n",
        "])\n",
        "lr_pipeline.fit(X_train, y_train)\n",
        "lr_pred_val = lr_pipeline.predict(X_val)\n",
        "lr_rmse = np.sqrt(mean_squared_error(y_val, lr_pred_val))\n",
        "print(\"Linear Regression Validation RMSE:\", lr_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 3 - Support Vector Machine (With Normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Takes too long ...\n",
        "# svm_pipeline = Pipeline([\n",
        "#     ('scaler', StandardScaler()),\n",
        "#     ('svm', SVR())\n",
        "# ])\n",
        "# svm_pipeline.fit(X_train, y_train)\n",
        "# svm_pred_val = svm_pipeline.predict(X_val)\n",
        "# svm_rmse = np.sqrt(mean_squared_error(y_val, svm_pred_val))\n",
        "# print(\"SVM Validation RMSE:\", svm_rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MijyTZNkhXpb"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1 - Final Training And Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LightGBM submission saved to submission_lgb.csv\n"
          ]
        }
      ],
      "source": [
        "# Retrain final LightGBM model on the full training data using the best iteration from validation\n",
        "final_lgb_train = lgb.Dataset(X, label=y)\n",
        "final_lgb_model = lgb.train(\n",
        "    lgb_params,\n",
        "    final_lgb_train,\n",
        "    num_boost_round=lgb_model.best_iteration,\n",
        "    callbacks=[lgb.log_evaluation(100)]\n",
        ")\n",
        "\n",
        "# Predict on the test set using the final model\n",
        "lgb_test_preds = final_lgb_model.predict(X_test, num_iteration=final_lgb_model.best_iteration)\n",
        "\n",
        "# Prepare submission using df_test original IDs\n",
        "submission_lgb = pd.DataFrame({'id': df_test['id'], 'Listening_Time_minutes': lgb_test_preds})\n",
        "submission_lgb.to_csv('submission_lgb.csv', index=False)\n",
        "print(\"LightGBM submission saved to submission_lgb.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2 - Final Training And Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression submission saved to submission_lr.csv\n"
          ]
        }
      ],
      "source": [
        "final_lr_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lr', LinearRegression())\n",
        "])\n",
        "final_lr_pipeline.fit(X, y)\n",
        "lr_test_preds = final_lr_pipeline.predict(X_test)\n",
        "\n",
        "# Prepare submission using df_test original IDs\n",
        "submission_lr = pd.DataFrame({'id': df_test['id'], 'Listening_Time_minutes': lr_test_preds})\n",
        "submission_lr.to_csv('submission_lr.csv', index=False)\n",
        "print(\"Linear Regression submission saved to submission_lr.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 3 - Final Training And Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Final retraining of the SVM pipeline on full training data\n",
        "# final_svm_pipeline = Pipeline([\n",
        "#     ('scaler', StandardScaler()),\n",
        "#     ('svm', SVR())\n",
        "# ])\n",
        "# final_svm_pipeline.fit(X, y)\n",
        "\n",
        "# # Predict on the test set\n",
        "# svm_test_preds = final_svm_pipeline.predict(X_test)\n",
        "\n",
        "# # Prepare submission using df_test original IDs\n",
        "# submission_svm = pd.DataFrame({'id': df_test['id'], 'Listening_Time_minutes': svm_test_preds})\n",
        "# submission_svm.to_csv('submission_svm.csv', index=False)\n",
        "# print(\"SVM submission saved to submission_svm.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPuBnDr5QL+/V81mOM+Il8t",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
